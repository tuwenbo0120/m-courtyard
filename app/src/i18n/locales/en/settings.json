{
  "title": "Settings",
  "environment": {
    "title": "Environment",
    "chip": "Chip",
    "memory": "Memory",
    "os": "Operating System",
    "python": "Python Environment",
    "pythonReady": "Ready",
    "pythonNotReady": "Not configured",
    "mlxLm": "mlx-lm",
    "mlxLmReady": "v{{version}}",
    "mlxLmNotReady": "Not installed",
    "uv": "uv (Package Manager)",
    "uvReady": "Available",
    "uvNotReady": "Not found",
    "ollama": "Ollama",
    "ollamaReady": "Installed",
    "ollamaNotReady": "Not installed",
    "setupButton": "Set Up Python Environment",
    "setupRunning": "Setting up...",
    "setupSuccess": "Environment configured successfully!",
    "setupError": "Setup failed: {{error}}",
    "refreshButton": "Refresh",
    "installMlxLm": "Install mlx-lm Training Framework",
    "installMlxLmDesc": "Will install mlx-lm (Apple Silicon training framework) in virtual environment using uv",
    "setupDesc": "Will create a Python virtual environment and install mlx-lm training framework",
    "browseModelDir": "Select {{source}} model directory",
    "installUv": "Install uv Package Manager",
    "uvInstalling": "Installing uv...",
    "installUvDesc": "Will download and install uv (fast Python package manager) from the official source",
    "uvInstallSuccess": "uv installed successfully! You can now set up the Python environment."
  },
  "theme": {
    "title": "Theme",
    "midnight": "Midnight",
    "midnightDesc": "Default dark theme",
    "ocean": "Ocean",
    "oceanDesc": "Deep blue tones",
    "sunset": "Sunset",
    "sunsetDesc": "Warm amber tones",
    "nebula": "Nebula",
    "nebulaDesc": "Cosmic violet tones",
    "light": "Light",
    "lightDesc": "Clean light theme"
  },
  "language": {
    "title": "Language",
    "current": "Current Language",
    "en": "English",
    "zhCN": "简体中文"
  },
  "about": {
    "title": "About",
    "version": "Version",
    "description": "Say Goodbye to Complexity, Easily Create Your AI Model",
    "github": "GitHub Repository"
  },
  "downloadSource": {
    "title": "Model Download Source",
    "desc": "Choose the default source for online model downloads. Models will be automatically fetched from this source during training.",
    "huggingface": "HuggingFace Official",
    "huggingfaceDesc": "Default, may need VPN in China",
    "hfMirror": "HF Mirror",
    "hfMirrorDesc": "China acceleration, recommended",
    "modelscope": "ModelScope",
    "modelscopeDesc": "Direct access in China, fewer models",
    "modelscopeWarn": "ModelScope does not support MLX model auto-download. We recommend switching to \"HF Mirror\" for China acceleration + full model support."
  },
  "storage": {
    "title": "Storage",
    "dataDir": "Data Directory",
    "openInFinder": "Open in Finder",
    "modelPaths": "Model Storage Locations",
    "modelPathsDesc": "Custom scan paths for each model source. Leave empty to use system defaults.",
    "hfPath": "HuggingFace Models",
    "msPath": "ModelScope Models",
    "ollamaPath": "Ollama Models",
    "defaultPath": "Default path",
    "effectivePath": "Effective path",
    "ollamaPathValid": "Custom Ollama path is valid ({{count}} model folders detected).",
    "ollamaPathInvalidLayout": "Custom Ollama path '{{path}}' is missing manifests/registry.ollama.ai/library layout.",
    "ollamaPathNoModels": "Custom Ollama path '{{path}}' has valid layout but no models were found.",
    "ollamaApplyFailed": "Custom path was saved, but failed to apply to Ollama daemon: {{error}}",
    "ollamaResetFailed": "Failed to reset Ollama path to default: {{error}}",
    "ollamaResetApplied": "Ollama path has been reset to default and daemon restarted.",
    "ollamaPathLayoutMissing": "Warning: custom path layout is invalid (missing manifests/registry.ollama.ai/library).",
    "ollamaPathNoModelHint": "Warning: custom path is valid but no Ollama models were detected.",
    "ollamaEffectivePathPersistHint": "Note: Reset was applied and Ollama restarted, but the effective path is still the custom one. This usually means a persistent OLLAMA_MODELS env variable exists (e.g. a permanent launchctl entry or export in ~/.zshrc) that takes effect after each restart. Run `launchctl unsetenv OLLAMA_MODELS` in Terminal and restart Ollama to fully clear it.",
    "exportPath": "GGUF Export Directory",
    "exportPathDesc": "Output directory for GGUF file exports. Leave empty to use the project directory. (Not related to Ollama export path.)",
    "exportDefaultHint": "Default output pattern: {{path}}",
    "browse": "Change",
    "resetDefault": "Reset",
    "default": "Default",
    "custom": "Custom"
  }
}
