{
  "appName": "M-Courtyard",
  "appDescription": "Say Goodbye to Complexity, Easily Create Your AI Model",
  "loading": "Loading...",
  "save": "Save",
  "cancel": "Cancel",
  "delete": "Delete",
  "confirm": "Confirm",
  "create": "Create",
  "edit": "Edit",
  "search": "Search",
  "settings": "Settings",
  "error": "Error",
  "success": "Success",
  "warning": "Warning",
  "close": "Close",
  "back": "Back",
  "next": "Next",
  "start": "Start",
  "stop": "Stop",
  "retry": "Retry",
  "noData": "No data",
  "browse": "Browse",
  "import": "Import",
  "export": "Export",
  "select": "Select",
  "apply": "Apply",
  "reset": "Reset",
  "running": "Running",
  "completed": "Completed",
  "failed": "Failed",
  "ready": "Ready",
  "notReady": "Not Ready",
  "comingSoon": "Coming Soon",
  "environment": "Environment",
  "hardware": "Hardware",
  "quickActions": "Quick Actions",
  "setupHint": "Python environment not configured. Click here to set up.",
  "mlxHint": "mlx-lm training framework not installed. Click here to install (Settings â†’ Configure Python Environment).",
  "importAndClean": "Import files and clean data",
  "configAndTrain": "Configure parameters and train",
  "testModel": "Test your fine-tuned model",
  "exportOllama": "Export model to Ollama",
  "envAndLang": "Environment and language settings",
  "dragDropHint": "Drag and drop files here, or click to browse",
  "formatBytes": "{{size}} bytes",
  "openFolder": "Open Folder",
  "openAdapterFolder": "Open Adapter Folder",
  "openModelFolder": "Open Model Folder",
  "clearRecords": "Clear Records",
  "clearLogs": "Clear Logs",
  "copyLog": "Copy Log",
  "copied": "Copied",
  "view": "View",
  "confirmDeleteTitle": "Confirm Delete",
  "confirmDeleteMsg": "Are you sure you want to delete {{name}}? This action cannot be undone.",
  "selectProjectHint": "Please select a project from the sidebar first",
  "resetDefaults": "Reset to Defaults",
  "clearAll": "Clear All",
  "openFinderTitle": "Open project folder in Finder",
  "firstSetup": {
    "title": "Setting up for the first time...",
    "configuring": "Configuring environment",
    "installing": "Installing dependencies",
    "complete": "Setup complete!"
  },
  "taskLock": {
    "datasetGenerating": "Dataset generation in progress, please wait",
    "modelTraining": "Model training in progress, please wait",
    "otherProject": "Project \"{{name}}\" is {{task}}, resources occupied",
    "taskGenerating": "generating data",
    "taskTraining": "training model"
  },
  "modelSelector": {
    "modelCacheDir": "Model Cache",
    "openModelCache": "Open model cache directory",
    "downloaded": "Downloaded",
    "pulled": "Downloaded",
    "more": "More",
    "unavailableSource": "(unavailable from this source)",
    "downloadFrom": "Models will be auto-downloaded from {{source}} and cached locally.",
    "sourceHuggingface": "HuggingFace",
    "sourceHfMirror": "HF Mirror",
    "sourceModelscope": "ModelScope",
    "onlineBrands": {
      "qwen": "Qwen",
      "deepseek": "DeepSeek",
      "glm": "GLM",
      "llama": "Llama",
      "gptoss": "GPT-OSS",
      "kimi": "Kimi",
      "mistral": "Mistral",
      "phi": "Phi"
    },
    "modelscopeWarnInline": "Current source is ModelScope, which does not support MLX model auto-download. Go to",
    "settingsLink": "Settings",
    "modelscopeWarnSuffix": "to switch to \"HF Mirror\" for China acceleration + full support.",
    "mlxHint": "Apple Silicon optimized MLX quantized models. Switch download source in",
    "mlxHintSuffix": "(\"HF Mirror\" recommended for China users).",
    "modelDesc": {
      "balanced": "Recommended, balanced",
      "lightweight": "Lightweight & fast",
      "versatile": "Versatile all-rounder",
      "reasoning": "Strong reasoning",
      "reasoningGeneral": "Reasoning + general",
      "reasoningLight": "Lightweight reasoning",
      "codeStrong": "Strong coding capability",
      "higherQuality": "Higher quality",
      "topRated": "Top-rated popular model",
      "popularGeneral": "Popular for general tasks",
      "openaiFamily": "OpenAI open-source model"
    },
    "ollamaLinks": {
      "website": "Ollama Website",
      "library": "Ollama Model Library",
      "websiteDesc": "Download & install",
      "libraryDesc": "Browse all models"
    },
    "hfLinks": {
      "official": "HuggingFace Official",
      "mirror": "HF Mirror",
      "modelscope": "ModelScope",
      "allModels": "All MLX Models",
      "officialDesc": "May need VPN in China",
      "mirrorDesc": "Direct access in China",
      "modelscopeDesc": "Direct access in China"
    },
    "rename": "Rename",
    "delete": "Delete",
    "sourceLabels": {
      "ollama": "Ollama",
      "trained": "Trained Adapters"
    },
    "disabledReason": {
      "ollamaNoLora": "GGUF format, not compatible with MLX LoRA training",
      "trainedNotBase": "LoRA adapter, not a base model",
      "adapterNoGen": "Adapters cannot be used for data generation",
      "ollamaOnly": "Only Ollama models are supported",
      "notInDaemon": "Not available in current Ollama daemon runtime path",
      "selectAdapter": "Please select a trained adapter"
    },
    "selectExisting": "Select Existing",
    "onlineModels": "Online Models (Auto-download)",
    "adjustSource": "Configure Sources",
    "localModels": "Local Models",
    "onlineTab": "Online",
    "scanStatus": "Scanned {{total}} local models, {{usable}} usable",
    "scanning": "Scanning...",
    "refresh": "Refresh",
    "scanningModels": "Scanning local models...",
    "noModelsFound": "No downloaded models found",
    "noModelsHint": "Select a recommended model from the \"Online\" tab, or browse folder",
    "usableCount": "{{count}} usable",
    "notUsable": "Not usable",
    "totalCount": " / {{count}} total",
    "openFolderTitle": "Open {{source}} folder",
    "openFolder": "Open Folder",
    "downloadSources": "Model Download Sources",
    "manageDownloaded": "Manage Downloaded",
    "downloadBtn": "Download",
    "downloading": "Downloading...",
    "downloadProgress": "{{percent}}%",
    "downloadSpeed": "{{speed}} MB/s",
    "downloadComplete": "Download complete",
    "downloadFailed": "Download failed",
    "downloadCancel": "Cancel",
    "downloadSize": "Total size: {{size}} MB",
    "downloadStarting": "Preparing download...",
    "stopDownload": "Stop",
    "downloadError": "Download error: {{message}}",
    "repoIdPlaceholder": "Enter HuggingFace model ID, e.g. mlx-community/Qwen3-4B-Instruct-2507-4bit",
    "customDownload": "Custom Model ID",
    "startDownload": "Download"
  },
  "ollamaPathMismatch": {
    "title": "Ollama daemon is not using your configured models path",
    "desc": "Ollama cannot find the selected model. This usually happens because the daemon was started without loading your custom path configured in Settings. Please check and fix the path.",
    "terminalHint": "Run the following command in Terminal, replace with your actual path, then restart Ollama:",
    "commandExample": "launchctl setenv OLLAMA_MODELS \"/path/to/your/models\"",
    "autoFix": "Apply configured path and restart Ollama automatically",
    "autoFixing": "Restarting Ollama...",
    "autoFixSuccess": "Path applied and Ollama restarted successfully. Please wait a moment then try generating again.",
    "autoFixError": "Auto-fix failed: {{error}}",
    "noCustomPath": "No custom path configured. Please set your Ollama models path in Settings first."
  }
}
